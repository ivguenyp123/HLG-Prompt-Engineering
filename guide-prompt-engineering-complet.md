# Guide Complet du Prompt Engineering
## De D√©butant Absolu √† Expert Tech

**Pour qui ?** Ce guide s'adresse √† des d√©butants complets en prompting, qui √©voluent vers des m√©tiers de l'informatique (d√©veloppeur, DevOps, Tech Lead, Data Engineer, etc.) et qui ont besoin de ma√Ætriser l'IA comme outil de travail quotidien.

**Dur√©e estim√©e :** 20-40 heures de pratique pour atteindre un niveau expert

---

## üìö Table des Mati√®res

1. [Introduction](#introduction)
2. [Niveau 1 : Fondamentaux](#niveau-1)
3. [Niveau 2 : Bases Solides](#niveau-2)
4. [Niveau 3 : Interm√©diaire](#niveau-3)
5. [Niveau 4 : Avanc√©](#niveau-4)
6. [Niveau 5 : Expert Tech](#niveau-5)
7. [Niveau 6 : Pro DevOps](#niveau-6)
8. [Cas d'Usage R√©els](#cas-usage)
9. [Erreurs Courantes](#erreurs)
10. [Exercices Pratiques](#exercices)
11. [Int√©gration Workflow](#workflow)
12. [Ressources & Conclusion](#ressources)

---

## Introduction {#introduction}

### Qu'est-ce qu'un Prompt ?

Un **prompt**, c'est le texte que tu donnes √† une IA pour lui demander quelque chose. C'est ton instruction, ta demande.

**Analogie :** L'IA est un coll√®gue super comp√©tent mais nouveau dans ton √©quipe. Il ne conna√Æt pas tes conventions de code, tes contraintes projet, ton architecture. Le prompt, c'est ta fa√ßon de lui expliquer le contexte et ce que tu attends.

### Pourquoi c'est Critique en Tech ?

L'IA devient un outil quotidien pour :
- G√©n√©rer du code (boilerplate, tests, scripts)
- Debugger (analyser logs, identifier bugs)
- Documenter (README, API docs)
- Automatiser (pipelines CI/CD)
- Architecturer (design patterns, choix tech)

**Exemple concret de la diff√©rence :**

```
‚ùå Prompt d√©butant : "Cr√©e un script Python"
‚Üí R√©sultat : Script g√©n√©rique inutilisable

‚úÖ Prompt expert : "Cr√©e un script Python 3.11+ qui lit un CSV avec 
pandas, valide le sch√©ma (colonnes: name, email, date), nettoie les 
emails (lowercase), exporte en JSON ISO 8601, avec logs structur√©s, 
type hints, docstrings Google style, et tests pytest pour 3 cas."
‚Üí R√©sultat : Code production-ready
```

### Progression en 6 Niveaux

1. **Fondamentaux** : Structure de base d'un prompt
2. **Bases Solides** : Role-playing, contexte, exemples
3. **Interm√©diaire** : Prompts structur√©s, cha√Ænage
4. **Avanc√©** : D√©composition, meta-prompting
5. **Expert Tech** : Architecture, code review, optimisation
6. **Pro DevOps** : CI/CD, IaC, monitoring, incident response

---

## Niveau 1 : Fondamentaux {#niveau-1}

### 1.1 Structure de Base (Les 4 Piliers)

Tout prompt efficace contient :

1. **CONTEXTE** : Qui ? Quoi ? Pourquoi ? Dans quel environnement ?
2. **T√ÇCHE** : Que veux-tu exactement ?
3. **CONTRAINTES** : Limites, standards, format, outils
4. **FORMAT** : Comment pr√©senter le r√©sultat

**Exemple D√©compos√© :**

```
[CONTEXTE] 
Je travaille sur une API REST en Node.js avec Express.
Notre √©quipe utilise JWT pour l'authentification.

[T√ÇCHE] 
Cr√©e un middleware d'authentification JWT.

[CONTRAINTES]
- Node.js 18+, Express 4.x
- Library: jsonwebtoken
- Gestion d'erreurs avec try/catch
- Secret JWT dans variable d'environnement

[FORMAT] 
Code complet avec imports, fonction middleware comment√©e, 
exemple d'utilisation sur une route, gestion des 3 cas : 
token valide, invalide, absent.
```

### 1.2 R√®gle d'Or : Sp√©cificit√©

‚ùå **Vague :** `Cr√©e un script bash`

‚úÖ **Sp√©cifique :**
```
Cr√©e un script bash qui :
- V√©rifie si Docker est install√© (command -v docker)
- Si absent : affiche erreur et exit 1
- Si pr√©sent : affiche la version
- Teste si daemon Docker tourne (docker ps)
- Utilise couleurs (vert=OK, rouge=erreur)
- Ajoute en-t√™te avec date/heure
```

**Checklist de Sp√©cificit√© :**
- [ ] Versions mentionn√©es ?
- [ ] Contraintes techniques explicites ?
- [ ] Format de sortie d√©fini ?
- [ ] Cas d'erreur consid√©r√©s ?
- [ ] Standards pr√©cis√©s ?

### 1.3 Verbes d'Action

**Pour Cr√©er :** cr√©e, g√©n√®re, d√©veloppe, impl√©mente, code

**Pour Analyser :** analyse, identifie, diagnostique, debug, trouve

**Pour Transformer :** refactorise, optimise, convertis, migre

**Pour Expliquer :** explique, documente, commente, d√©taille

**Pour Comparer :** compare, √©value, benchmark, critique

**Pour Tester :** teste, valide, v√©rifie, simule

### 1.4 Template de D√©marrage

```
CONTEXTE :
[Ton r√¥le, projet, stack technique, contraintes]

T√ÇCHE :
[Ce que tu veux pr√©cis√©ment]

CONTRAINTES :
- [Langage/version]
- [Outils/frameworks]
- [Standards/conventions]
- [Limites/restrictions]

FORMAT ATTENDU :
[Structure de la r√©ponse souhait√©e]
```

**Exercice Pratique :**

Am√©liore ce prompt : `Cr√©e un Dockerfile`

**Solution :**
```
CONTEXTE : App Node.js 18, Express, npm, port 3000

T√ÇCHE : Cr√©e un Dockerfile optimis√© production

CONTRAINTES :
- Image alpine pour taille minimale
- Multi-stage build
- Layer caching optimis√© (COPY package*.json avant COPY .)
- User non-root pour s√©curit√©
- Healthcheck sur /health
- Variables d'env : NODE_ENV, PORT

FORMAT : Dockerfile complet + commentaires expliquant chaque section
```

---

## Niveau 2 : Bases Solides {#niveau-2}

### 2.1 Role-Playing

Assigner un r√¥le change radicalement la qualit√©.

‚ùå **Sans r√¥le :**
```
Comment am√©liorer les performances de ma DB ?
```

‚úÖ **Avec r√¥le contextualis√© :**
```
Tu es un DBA senior PostgreSQL avec 10 ans d'exp√©rience sur des 
apps >10M requ√™tes/jour.

Ma table users (50M lignes) a des SELECT lents (>2s) sur la colonne 
email. Pas d'index dessus. Traffic : 5000 req/s en pic.

Propose 3 solutions par ordre de priorit√© avec :
- Impl√©mentation SQL concr√®te
- Impact attendu
- Risques et pr√©cautions
- Temps de mise en ≈ìuvre
```

### 2.2 Contexte Technique Riche

Plus de contexte = meilleure r√©ponse.

**Contexte Riche :**
```
STACK : Node.js 18, Express, MongoDB 6.0, Docker sur AWS ECS
PROBL√àME : GET /users/:id retourne en 1.5s (objectif < 200ms)
OBSERVATIONS :
- Pas de cache
- Logs : query Mongo prend 1.2s
- Mod√®le User a 15 champs, on en utilise 5
- 2M documents
- Pas d'index sur _id

CONTRAINTES : Pas de budget infra, deploy weekend only

Propose un plan d'optimisation √©tape par √©tape avec impact estim√©.
```

**Checklist du Bon Contexte :**
- [ ] Versions exactes
- [ ] M√©triques actuelles
- [ ] Objectifs chiffr√©s
- [ ] Contraintes (temps, budget, compatibilit√©)
- [ ] Ce qui a √©t√© tent√©

### 2.3 Few-Shot Prompting (Exemples)

Montre des exemples de ce que tu veux.

```
Je veux des tests Jest pour mes fonctions JavaScript. Voici le style :

EXEMPLE 1 :
describe('calculateTotal', () => {
  it('should return sum of positive numbers', () => {
    expect(calculateTotal([1, 2, 3])).toBe(6);
  });
  
  it('should return 0 for empty array', () => {
    expect(calculateTotal([])).toBe(0);
  });
});

EXEMPLE 2 :
describe('validateEmail', () => {
  it('should accept valid email', () => {
    expect(validateEmail('test@example.com')).toBe(true);
  });
});

Maintenant, cr√©e des tests dans ce style pour :

function findUserById(users, id) {
  return users.find(user => user.id === id) || null;
}

Couvre : utilisateur trouv√©, ID inexistant, tableau vide, ID null.
```

### 2.4 Chain of Thought (Raisonnement √âtape par √âtape)

Demande √† l'IA de d√©composer.

```
Mon conteneur Docker ne d√©marre pas :
"exec user process caused: exec format error"

Analyse en suivant ces √©tapes :

1. IDENTIFIER : Que signifie cette erreur ?
2. CAUSES : Liste 5 causes potentielles
3. DIAGNOSTIC : Pour chaque cause, donne une commande de v√©rification
4. SOLUTION : Propose une solution pour la cause la plus probable
5. PR√âVENTION : Comment √©viter √ßa √† l'avenir ?

D√©taille ton raisonnement.
```

### 2.5 It√©ration

Ton premier prompt n'est jamais le meilleur.

```
It√©ration 1 : "Cr√©e un script Python de scraping"
‚Üí Trop g√©n√©rique

It√©ration 2 : "Script Python qui scrape les titres sur 
https://news.ycombinator.com avec BeautifulSoup"
‚Üí Mieux mais pas de gestion d'erreurs

It√©ration 3 : "Le script pr√©c√©dent est bien, mais ajoute :
- Timeout 10s avec retry 3 fois
- Sauvegarde en CSV avec date
- User-Agent personnalis√©
- Logging niveau INFO"
‚Üí Production-ready ‚úÖ
```

### 2.6 Contraintes Explicites

D√©finis ce que tu NE veux PAS.

```
Cr√©e une fonction JS de validation de mot de passe.

R√àGLES :
- Min 8 caract√®res
- 1 majuscule, 1 minuscule, 1 chiffre, 1 sp√©cial

CONTRAINTES :
- Pas de regex compliqu√©e (je veux comprendre)
- Pas de librairie externe
- Pas de eval()
- Code comment√© ligne par ligne

FORMAT :
- Fonction pure, return boolean
- Objet d√©tails avec r√®gles cass√©es si invalide
- Tests unitaires simples
```

---

## Niveau 3 : Interm√©diaire {#niveau-3}

### 3.1 Prompts Structur√©s avec D√©limiteurs

Utilise XML-like ou Markdown pour clart√©.

```
<context>
Application Flask 2.3, Python 3.11, d√©ploy√©e sur Heroku.
Endpoint qui upload des fichiers images.
</context>

<task>
Ajoute validation pour :
1. V√©rifier type image (JPEG, PNG, WebP)
2. Limiter √† 5MB
3. Retourner 400 si validation √©choue
</task>

<current_code>
```python
@app.route('/upload', methods=['POST'])
def upload_file():
    file = request.files['image']
    filename = secure_filename(file.filename)
    file.save(os.path.join(app.config['UPLOAD_FOLDER'], filename))
    return jsonify({'success': True})
```
</current_code>

<constraints>
- Utilise Pillow pour v√©rifier le type r√©el
- Ne casse pas le comportement existant
- Logs des erreurs
- Messages en fran√ßais
</constraints>

<output_format>
1. Code modifi√© complet
2. Exemple de r√©ponse d'erreur JSON
3. Tests curl pour cas valide et invalide
</output_format>
```

### 3.2 Persona avec Contraintes de Communication

```
Tu es un mentor backend patient et p√©dagogue. Tu expliques les 
concepts complexes avec des analogies simples.

Explique-moi la diff√©rence entre synchrone et asynchrone en Node.js :

1. Avec une analogie du quotidien (restaurant, poste...)
2. Avec 2 exemples de code c√¥te √† c√¥te
3. Quand utiliser l'un ou l'autre

Maximum 300 mots. Ton amical.
```

### 3.3 Templates R√©utilisables

**Template Code Review :**

```
## CODE REVIEW REQUEST

Langage : [Python/Java/JS]
Contexte : [Description du module]

Code :
```[language]
[TON CODE]
```

Points d'attention :
- [ ] S√©curit√©
- [ ] Performance
- [ ] Maintenabilit√©
- [ ] Tests

Format :
1. Score global /10
2. Points forts (2-3)
3. Points d'am√©lioration avec code corrig√©
4. Risques identifi√©s
```

### 3.4 Negative Prompting

Dis ce que tu NE veux PAS.

```
Cr√©e un endpoint Express pour cr√©er un utilisateur.

CE QUE JE VEUX :
- Validation avec Joi
- Hash password avec bcrypt
- Return 201 avec user (sans password)

CE QUE JE NE VEUX PAS :
- Pas de MongoDB direct (on a un UserService)
- Pas de validation manuelle if/else
- Pas de password en clair dans logs
- Pas de console.log pour debug
- Pas de var, utilise const/let
```

### 3.5 Sequential Prompting

D√©coupe les t√¢ches complexes.

Au lieu de : "Cr√©e une app To-Do compl√®te avec React, Express, Mongo, auth, tests, deploy"

Fais :

**Prompt 1 - Architecture :**
```
Je veux cr√©er une app To-Do. Propose une architecture :
- Stack frontend
- Stack backend
- Base de donn√©es
- Authentification
- Hosting
Justifie chaque choix. Contrainte : gratuit/low-cost.
```

**Prompt 2 - Schema DB :**
```
On a choisi MongoDB. D√©finis le sch√©ma Mongoose pour :
- Users (email, password, createdAt)
- Todos (title, description, completed, userId, dates)
Avec validations, index, relations.
```

**Prompt 3 - Backend Endpoints :**
```
Voici le sch√©ma : [COLLE R√âSULTAT 2]
Cr√©e les endpoints Express pour CRUD Todos avec auth JWT.
```

---

## Niveau 4 : Avanc√© {#niveau-4}

### 4.1 Context Window Management

Pour gros fichiers (2000 lignes), ne colle pas tout.

**Mauvais :** Colle 2000 lignes, "Trouve les bugs"

**Bon - √âtape 1 :**
```
Voici ma structure :
src/
‚îú‚îÄ‚îÄ models/ (User.js 150L, Post.js 120L)
‚îú‚îÄ‚îÄ controllers/ (userController.js 300L ‚Üê PROBL√àME ICI)
‚îú‚îÄ‚îÄ routes/
‚îî‚îÄ‚îÄ services/

Erreurs 500 sur endpoints users. Probl√®me semble venir de 
userController.js.

Avant de voir le code, pose-moi 5 questions pour cibler le diagnostic.
```

**√âtape 2 :**
```
[APR√àS LES QUESTIONS]
Voici la fonction probl√©matique (50 lignes seulement) :
[CODE CIBL√â]
```

### 4.2 Meta-Prompting

Fais g√©n√©rer le prompt par l'IA.

```
G√©n√®re un prompt template pour cr√©er des scripts Bash de monitoring 
syst√®me (CPU, RAM, disk, network) avec alertes.

Le template doit inclure :
- Un r√¥le appropri√©
- Sections contextuelles
- Format de sortie structur√©
- Exemples few-shot
```

### 4.3 Constraint Satisfaction

Donne des contraintes contradictoires, force le compromis.

```
Cr√©e une fonction de rate limiting pour mon API Express.

CONTRAINTES (certaines conflictuelles, trouve le meilleur √©quilibre) :
1. Performance : 10k req/s sans latence
2. Persistance : survivre au red√©marrage
3. Simplicit√© : pas de d√©pendance si possible
4. Pr√©cision : par user, par IP, par endpoint
5. Co√ªt : gratuit/low-cost
6. Scalabilit√© : multi-instance (load balancer)

Propose 2 solutions :
- Solution A : Optimis√©e simplicit√©/performance
- Solution B : Optimis√©e pr√©cision/scalabilit√©

Pour chaque : code, trade-offs, sc√©narios d'usage
```

### 4.4 Systematic Decomposition

Pour probl√®mes ultra-complexes.

```
PROBL√àME :
Migrer app monolithe PHP 5.6 (200k lignes, 10 ans) vers microservices 
Node.js/Python. Prod ne peut pas s'arr√™ter. 6 mois.

D√âCOMPOSITION :

1. ANALYSE :
   - Quels sont les sous-probl√®mes ?
   - D√©pendances entre eux ?
   - Ordre de r√©solution optimal ?

2. PRIORISATION :
   - Par criticit√©, difficult√©, d√©pendances

3. PLAN D'ACTION :
   - Pour chaque sous-probl√®me : input, output, approche, tests

Commence par l'analyse. Ne code rien encore.
```

---

## Niveau 5 : Expert Tech {#niveau-5}

### 5.1 Architecture Decision Records (ADR)

```
# ARCHITECTURE DECISION REQUEST

## Contexte
App de messagerie temps r√©el.
- 50k users actifs/jour
- 500k messages/jour
- Stack : PHP monolithe + MySQL + polling HTTP/2s
- Latence messages 3-5s
- Serveurs surcharg√©s en heures de pointe

## Probl√®me
Migrer vers architecture temps r√©el performante sans tout recoder.

## Crit√®res de D√©cision
1. Latence messages < 100ms (poids 10/10)
2. Co√ªt infra < $500/mois (poids 8/10)
3. Compatibilit√© mobile iOS/Android (poids 9/10)
4. Effort migration < 3 mois, 2 devs (poids 7/10)
5. Scalabilit√© 500k users dans 2 ans (poids 8/10)

## Contraintes
- Team : 2 devs backend, 1 dev mobile
- Budget : $500/mois max
- Timeline : 3 mois
- Clients existants : compatibilit√© requise

## Demande
Propose 3 options architecturales avec :
1. Approche high-level (diagramme Mermaid/ASCII)
2. Trade-offs (matrice crit√®res vs options)
3. Stack technique sugg√©r√©e
4. Risques identifi√©s
5. Migration path depuis existant
6. Recommandation finale justifi√©e
```

### 5.2 Code Review Expert

```
# EXPERT CODE REVIEW

Tu es un Tech Lead senior, 15 ans d'XP. Reviews rigoureuses et constructives.

Code :
```[language]
[CODE]
```

Review Checklist (note /10 chaque cat√©gorie) :

1. Correctness & Logic
2. Security (injection, donn√©es sensibles, validation inputs)
3. Performance (complexit√© algo, N+1, memory leaks)
4. Error Handling
5. Testing (testabilit√©)
6. Maintainability (self-documenting, fonctions < 50L, SRP)
7. Standards & Best Practices

Output :
- ‚úÖ Approuv√© / ‚ö†Ô∏è Avec commentaires / ‚ùå Changements requis
- Score global /70
- Critical Issues (bloquants)
- Major Issues
- Minor Issues
- Positives
- Suggested Refactoring
```

### 5.3 Performance Optimization

```
# PERFORMANCE OPTIMIZATION

Code :
```python
def get_user_dashboard(user_id):
    user = db.query("SELECT * FROM users WHERE id = %s", user_id)
    posts = []
    for friend_id in user['friends']:
        friend_posts = db.query("SELECT * FROM posts WHERE user_id = %s", friend_id)
        posts.extend(friend_posts)
    for post in posts:
        post['comments'] = db.query("SELECT * FROM comments WHERE post_id = %s", post['id'])
        post['likes'] = db.query("SELECT COUNT(*) FROM likes WHERE post_id = %s", post['id'])
    return {'user': user, 'posts': sorted(posts, key=lambda x: x['created_at'])[:50]}
```

M√©triques actuelles :
- Temps r√©ponse : 3.2s
- Queries DB : 250-500 par requ√™te
- Load : 100 req/s en pic

Objectifs :
- Temps r√©ponse < 200ms (p95)
- Queries < 10
- Supporter 1000 req/s

Profiling : 95% du temps dans queries DB

Analyse :
1. Identification Bottlenecks (top 3 par impact)
2. Quick Wins (impact √©lev√©, effort faible)
3. Optimisations Majeures
4. Trade-offs
5. Plan d'Action Prioris√©
```

### 5.4 Documentation Technique Auto-G√©n√©r√©e

```
G√©n√®re un README.md pro pour ce projet.

Structure :

1. Titre et Badges (build, coverage, version, license)
2. Features (principales, ce qui rend unique)
3. Tech Stack (langages, frameworks, d√©pendances)
4. Getting Started
   - Prerequisites
   - Installation (step-by-step)
   - Configuration (env vars)
   - Running (dev, prod, tests)
5. Usage (exemples de code, screenshots si pertinent)
6. Architecture (diagramme Mermaid, explication composants)
7. Development
   - Project Structure (tree comment√©)
   - Running Tests
   - Code Style
8. Deployment
9. Contributing
10. License
11. Contact/Support

Format : Markdown propre, pr√™t √† commit.
```

---

## Niveau 6 : Pro DevOps {#niveau-6}

### 6.1 CI/CD Pipeline Generation

```
# CI/CD PIPELINE REQUEST

Project :
- Lang/Framework : Node.js 18, Express
- Tests : Jest, coverage > 80%
- Build : TypeScript compile
- Deploy : AWS ECS
- Environments : dev, staging, prod

Platform : GitLab CI

Requirements :

Triggers :
- Push sur branches
- MR
- Tags v*.*.*

Stages : lint ‚Üí test ‚Üí build ‚Üí security ‚Üí deploy-dev ‚Üí deploy-staging ‚Üí deploy-prod

Quality Gates :
- Coverage > 85%
- Linting : zero errors
- Security : no CRITICAL
- Build : successful

Deployments :
- Dev : auto sur develop
- Staging : auto sur main
- Prod : manuel via tag + approval

Notifications : Slack #deploys

Caching : dependencies, Docker layers

Secrets : GitLab CI variables

Contraintes :
- Pipeline < 8 min
- Zero-downtime deploy (blue-green)
- Auto-rollback si healthcheck fail 3x

Output :
1. .gitlab-ci.yml complet
2. Scripts si n√©cessaires
3. Doc des secrets √† configurer
4. Proc√©dure rollback
5. Troubleshooting guide
```

### 6.2 Infrastructure as Code

```
# IaC REQUEST

Goal : Deploy scalable web app avec database

Cloud : AWS
Tool : Terraform

Components :
- Compute : ECS Fargate, auto-scaling
- Networking : VPC, subnets (public/private), ALB, security groups
- Storage : RDS PostgreSQL, S3
- Monitoring : CloudWatch, alerting

Requirements :
- Environment : prod
- HA : yes, multi-AZ
- DR : backup daily, RTO/RPO < 1h
- Budget : < $500/month
- Compliance : GDPR

Output :
1. Main .tf files (modularized)
2. Variables file with doc
3. Outputs (endpoints, connection strings)
4. README (prerequisites, deploy, destroy, cost estimation)
5. State management strategy
```

### 6.3 Observability Stack

```
# OBSERVABILITY STACK

App : Microservices, Node.js + Python, Kubernetes
Traffic : 1000 req/min (3000 en pic)

Requirements :

Metrics (System + Business) :
- System : CPU, RAM, request rate, latency (p50/p95/p99), error rate
- Business : orders/hour, signups/day, conversion funnel

Logging :
- Structured JSON logs
- Levels : DEBUG, INFO, WARN, ERROR
- Correlation IDs pour tracing
- Retention : 30 jours

Tracing :
- End-to-end request tracing
- Service dependency map

Alerting :
- Critical : service down, error rate >5%, latency >1s p95
- Warning : autres conditions

Dashboards :
- Health overview
- Per-service deep dive
- Business metrics

Tech Stack : Prometheus + Loki + Jaeger + Grafana

Output :
1. Architecture (Mermaid diagram)
2. Config files (Prometheus, Fluentd, Jaeger)
3. Instrumentation code (exemples par langage)
4. Alerting rules
5. Dashboard templates JSON
6. Runbook (interpr√©ter m√©triques et alertes)
```

### 6.4 Runbook Template

```
# RUNBOOK: [SERVICE NAME]

Service Description :
- Purpose : [√Ä quoi sert ce service]
- Dependencies : [Services/DBs/APIs]
- SLA : [99.9% uptime, latency < 200ms]

Architecture : [Mermaid diagram]

Key Metrics :
| Metric | Normal | Warning | Critical |
|--------|---------|---------|----------|
| Request Rate | 100-500 | <50 ou >1000 | <10 ou >2000 |
| Latency p95 | <200ms | >500ms | >1000ms |

---

## INCIDENT RESPONSE

### 1. Service is Down (HTTP 5xx)

Symptoms : Healthcheck failing, 500s, alertes

Immediate Actions (< 5 min) :
1. Check pods : kubectl get pods -n prod
2. Check recent deploys : git log -10
3. If recent deploy : Rollback
   ```
   kubectl rollout undo deployment/[name] -n prod
   ```
4. Check logs : kubectl logs -f deployment/[name]

Investigation (< 15 min) :
- External dependencies (DB, Redis, APIs)
- Resource constraints (OOMKilled?)
- Recent config changes

Escalation (if not resolved in 15 min) :
- Primary : @tech-lead (Slack/Phone)
- Secondary : @senior-dev

Communication Template :
```
üö® INCIDENT - [Service] DOWN
Status: Investigating
Impact: [User impact]
Started: [Time]
Actions: [List]
Next update: 15 min
```

---

### 2. High Latency

[Similar structure]

---

## Useful Commands

Check Health : `curl https://[service]/health`
Tail Logs : `[command]`
DB Connection : `[command]`
Metrics Dashboard : [Link]

---

## Postmortem Template

```markdown
# Postmortem: [Incident]

Summary : [One paragraph]

Impact :
- Duration : [start - end]
- Affected users : [%]

Root Cause : [Detailed]

Timeline :
- HH:MM - [Event]

Resolution : [What fixed it]

Action Items :
- [ ] [Action 1] - Owner: @name - Due: date
```
```

### 6.5 Secrets Management Audit

```
# SECRETS AUDIT

Current State :

Inventory (tous les endroits o√π des secrets existent) :
- [ ] Code source (git history)
- [ ] Config files (.env)
- [ ] CI/CD variables
- [ ] Container env vars
- [ ] Kubernetes secrets
- [ ] Developer machines
- [ ] Documentation
- [ ] Logs

Secret Types :
- DB credentials
- API keys
- JWT signing keys
- Encryption keys
- SSL/TLS certs

Risk Assessment (pour chaque secret) :
- Exposure : o√π stock√© ? qui y acc√®de ?
- Impact : si compromis ?
- Rotation : dernier changement ?

---

Remediation Plan :

Phase 1 (< 24h) :
1. Scan git history (truffleHog, gitleaks)
2. Rotate exposed secrets
3. Remove secrets from code

Phase 2 (< 1 week) :
1. Implement tool (Vault, AWS Secrets Manager, etc.)
2. Migrate secrets
3. Update CI/CD
4. Document process

Phase 3 (< 1 month) :
1. Rotation policy (DB: 90d, API keys: 180d)
2. Monitoring (alert on unauthorized access)
3. Developer training

---

Implementation :
[Config d√©taill√©e de l'outil]

Code Changes :
```language
// Before
const DB_PASSWORD = "hardcoded";

// After
const DB_PASSWORD = await secretsManager.getSecret("db-password");
```

Validation :
- [ ] No secrets in git
- [ ] All secrets in management tool
- [ ] Access logged
- [ ] Rotation enforced
```

---

## Cas d'Usage R√©els {#cas-usage}

### 7.1 Migration de Technologie

```
# MIGRATION PLAN: [OLD TECH] ‚Üí [NEW TECH]

Executive Summary :
- What : [Description]
- Why : [Raisons business/tech]
- When : [Timeline]
- Risk : [Low/Medium/High]

Current State :
- Tech Stack : [Details]
- Scale : [M√©triques]
- Pain Points : [Liste]

Target State :
- New Stack : [Details]
- Benefits : [Avec m√©triques]

Migration Strategy : Strangler Fig (3 mois)

Phase 1 - Preparation (2 weeks) :
- Setup new stack en parall√®le
- Dual-write adapter
- Feature flags
- Monitoring

Phase 2 - Shadow Mode (2 weeks) :
- Route copy traffic (no user impact)
- Compare responses
- Fix discrepancies

Phase 3 - Canary (2 weeks) :
- 5% ‚Üí 25% ‚Üí 50% traffic

Phase 4 - Full Migration (2 weeks) :
- 100% traffic

Phase 5 - Cleanup (2 weeks) :
- Remove feature flags
- Remove old code

Risk Management :
| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|------------|
| Data loss | Low | CRITICAL | Dual-write, backups |

Success Metrics :
- Zero data loss
- Downtime < 5 min total
- Performance improved by X%
```

### 7.2 Incident Postmortem

```
# Postmortem: [Incident Title]

Date : 2024-11-18
Authors : [@name1, @name2]
Severity : SEV-1

---

Summary : [2-3 phrases pour non-tech stakeholders]

TL;DR :
- What broke : [Service]
- Impact : X users, Y minutes
- Root cause : [One sentence]
- Fix : [One sentence]

---

Impact :

User Impact :
- Affected : X% users (N users)
- Duration : [Start] to [End] (N min)
- Symptoms : [Ce que users ont v√©cu]

Business Impact :
- Revenue : ~$X lost
- SLA : Breached [if applicable]

---

Timeline (UTC) :

| Time | Event |
|------|-------|
| 14:23 | üî¥ Deployment v2.4.0 started |
| 14:26 | ‚ö†Ô∏è Error spike 0.1% ‚Üí 15% |
| 14:27 | üö® PagerDuty alert |
| 14:28 | üëÄ @alice investigating |
| 14:35 | üîç Identified: DB migration broke FK constraints |
| 14:38 | üîÑ Rollback decision |
| 14:43 | ‚úÖ Service recovered |

Total : 20 min

---

Root Cause Analysis (5 Whys) :

1. Why did service fail ? ‚Üí DB queries errored
2. Why did queries fail ? ‚Üí FK constraint violations
3. Why violations ? ‚Üí Migration added FK, data had orphaned records
4. Why orphaned records ? ‚Üí Previous bug allowed it
5. Why didn't we catch ? ‚Üí Staging DB was clean

Root Cause : Migration conflicted with dirty data. Staging ‚â† prod data quality.

---

What Went Well üëç :
1. Fast detection (3 min)
2. Clear ownership
3. Successful rollback

What Went Wrong üëé :
1. No data validation before migration
2. Staging parity issue
3. No gradual rollout

---

Action Items :

Immediate (This Week) :
- [ ] Clean orphaned data - @bob - Nov 20
- [ ] Test rollback - @alice - Nov 21

Short-term (This Month) :
- [ ] Pre-migration validation script - @charlie - Nov 30
- [ ] Improve staging data - @david - Dec 5
- [ ] Canary for DB changes - @alice - Dec 10

Long-term (Next Quarter) :
- [ ] Automated data quality checks - @emily - Jan 15
- [ ] Migration risk scoring - @frank - Jan 30

---

Lessons Learned :
1. Always validate data before adding constraints
2. Staging must mirror prod data characteristics
3. DB changes need gradual rollout too

---

Postmortem reviewed by : @tech-lead, @vp-eng
Date finalized : 2024-11-20
```

---

## Erreurs Courantes {#erreurs}

### Erreur 1 : Prompt Trop Vague

‚ùå `Aide-moi √† coder`

‚úÖ Solution : Ajoute contexte, t√¢che pr√©cise, contraintes, format

### Erreur 2 : Contexte Insuffisant

‚ùå `Mon code ne marche pas`

‚úÖ Solution : Donne stack, code, erreur, environnement, ce qui a √©t√© tent√©

### Erreur 3 : Demander Trop en Une Fois

‚ùå `Cr√©e une app e-commerce compl√®te avec tout`

‚úÖ Solution : D√©compose en 5-10 prompts s√©quentiels

### Erreur 4 : Oublier les Contraintes

‚ùå `Cr√©e un script de backup`

‚úÖ Solution : Pr√©cise versions, format, s√©curit√©, gestion erreurs

### Erreur 5 : Ne Pas It√©rer

‚ùå [Re√ßoit r√©ponse imparfaite] "Bon, √ßa ira..."

‚úÖ Solution : TOUJOURS it√©rer 2-3 fois minimum

### Erreur 6 : Copier-Coller Sans Comprendre

‚ùå [Copie code IA] [Colle direct en prod] [üí•]

‚úÖ Solution : Checklist avant utilisation :
- [ ] Je comprends chaque ligne
- [ ] Test√© localement
- [ ] Edge cases v√©rifi√©s
- [ ] Adapt√© √† mon contexte
- [ ] Tests ajout√©s

### Erreur 7 : Ignorer les Bonnes Pratiques

‚ùå `Cr√©e un endpoint` ‚Üí [Code sans validation, sans tests]

‚úÖ Solution : Toujours demander code "production-ready" avec validation, logs, tests, doc

### Erreur 8 : Versions Vagues

‚ùå `Cr√©e un Dockerfile` ‚Üí [Re√ßoit Python 3.7, ton app = 3.11]

‚úÖ Solution : TOUJOURS pr√©ciser versions exactes

### Erreur 9 : N√©gliger la Performance

‚ùå `Filtre des users` ‚Üí [Code O(n¬≤)]

‚úÖ Solution : Mentionne le scale d√®s le d√©but

### Erreur 10 : Oublier la Maintenance

‚ùå [Code sans doc, sans tests]

‚úÖ Solution : Pense long terme, demande doc + tests + exemples

---

## Exercices Pratiques {#exercices}

### D√©butant (30 min)

Transforme ces prompts faibles :

1. `√âcris du code Java`
2. `Mon API est lente`
3. `Aide avec Docker`
4. `Explique Git`

### Interm√©diaire (1h)

Cr√©e un template r√©utilisable pour une t√¢che que tu fais souvent.

### Avanc√© (2h)

Bug en production : app crashe de fa√ßon intermittente. Cr√©e une s√©rie de 5-7 prompts pour diagnostiquer.

### Expert (4-6h)

Con√ßois l'architecture d'une plateforme de streaming vid√©o (mini-YouTube) via prompting uniquement. Livrables : ADR, diagramme, stack justifi√©e, estimation co√ªts, plan de migration.

---

## Int√©gration Workflow {#workflow}

### Dans l'IDE

```typescript
/**
 * Sort User objects by multiple criteria with priority
 * 
 * Requirements:
 * - Primary: status (active > inactive > suspended)
 * - Secondary: created_at (newest first)
 * - Tertiary: name (alphabetical)
 * - Immutable (don't modify original)
 * - Performance: O(n log n)
 */
function sortUsersByPriority(users: User[]): User[] {
  // L'IA compl√®te ici
}
```

### Code Review Avant PR

```
Fais une code review rigoureuse.

CONTEXT : [Feature description]
STACK : [Technologies]

CODE :
[Files]

REVIEW : Security, Correctness, Performance, Maintainability, Testing, Style

FORMAT : CRITICAL/MAJOR/MINOR issues, code corrig√©, score /10
```

### Debugging Workflow

**√âtape 1 - Collecte :**
```
Je dois debugger [probl√®me]. Dis-moi quelles infos tu as besoin.
```

**√âtape 2 - Analyse :**
[Fournis les infos demand√©es]

**√âtape 3 - Solutions :**
```
Propose 3 solutions possibles avec probabilit√© de succ√®s pour chaque.
```

**√âtape 4 - Impl√©mentation :**
```
On essaie la solution 1. Donne-moi le code/commandes exactes.
```

---

## Ressources & Conclusion {#ressources}

### Progression Recommand√©e

**Semaine 1-2 : Fondamentaux**
- Pratique structure 4 piliers
- Ajoute contraintes syst√©matiquement
- Utilise role-playing

**Semaine 3-4 : Interm√©diaire**
- Templates r√©utilisables
- Sequential prompting
- Few-shot learning

**Mois 2 : Avanc√©**
- Meta-prompting
- Systematic decomposition
- Context window management

**Mois 3+ : Expert**
- ADR via prompting
- Pipelines CI/CD complets
- Optimisations complexes

### Checklist du Prompt Parfait

- [ ] Contexte complet (stack, versions, scale)
- [ ] T√¢che pr√©cise et non ambigu√´
- [ ] Contraintes explicites (tech + business)
- [ ] Format de sortie d√©fini
- [ ] Exemples si pattern sp√©cifique
- [ ] Gestion d'erreurs mentionn√©e
- [ ] Standards/best practices pr√©cis√©s

### Principe d'Or

**"Un prompt expert, c'est comme une spec technique compl√®te : quelqu'un qui ne conna√Æt pas le projet doit pouvoir tout comprendre et impl√©menter."**

### Pour Aller Plus Loin

- Exp√©rimente quotidiennement
- It√®re toujours (minimum 2-3 fois)
- Cr√©e ta biblioth√®que de templates
- Partage avec ton √©quipe
- Adapte les techniques √† ton domaine

### Conclusion

Le prompt engineering n'est pas de la "magie" - c'est une comp√©tence technique qui s'apprend et se pratique. Plus tu es pr√©cis, structur√©, et contextuel, meilleurs seront tes r√©sultats.

**L'IA est ton coll√®gue super comp√©tent. Traite-le comme tel : donne-lui le contexte complet, les contraintes claires, et les attentes pr√©cises. Tu ne serais pas vague avec un humain - ne le sois pas avec une IA.**

Bon prompting ! üöÄ

---

**Version :** 1.0  
**Derni√®re mise √† jour :** Novembre 2024  
**License :** Creative Commons BY-SA 4.0  
**Contribuer :** [Tes retours sont les bienvenus]

